{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YSCGJouOQN7"
   },
   "source": [
    "# Julia Notebook\n",
    "\n",
    "Based on the demo from NN tutorial 1.\n",
    "\n",
    "1. Google Colab\n",
    "2. Data loading\n",
    "3. MLP forward pass\n",
    "4. Batching/vectorization\n",
    "5. Automatic differentiation\n",
    "6. MLP gradient descent\n",
    "7. MLP using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDBVj8S5OQN_"
   },
   "source": [
    "# 1) Google Colab\n",
    "\n",
    "To activate your Colab notebook for GPU usage, go to `Runtime > Change runtime type` and select `GPU` as hardware accelerator. Then, run the following to check your device availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZqmSdREOWHi",
    "outputId": "86b7811a-0b17-4dab-c611-f9eeca617185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 24 11:30:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.09       Driver Version: 461.09       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 165... WDDM  | 00000000:57:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8     4W /  N/A |    134MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_x3YHRBOQOB"
   },
   "source": [
    "# 2) Loading the data\n",
    "\n",
    "Load each datafile into jupyter, extract their $x$ and $y$ entries, and store the results in matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PNDOrliAOQOB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvqBfUlNOQOC",
    "outputId": "0bd7d59e-013e-4040-b873-0503d7930c9c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points: (10, 676)\n",
      "targets: (10, 2)\n"
     ]
    }
   ],
   "source": [
    "# x: (n_samples, x_ver_dim, x_hor_dim) with x_ver_dim = x_hor_dim = 512 (so in total 512^2 pixel)\n",
    "# y: (n_samples, y_dim) with y_dim=2 (the julia constant and the starting coordinate)\n",
    "\n",
    "dataList = []\n",
    "ytargetList = []\n",
    "# load first 10 datapoints for testing\n",
    "for fileIndex in range(10):\n",
    "    with open('../trainingData/data'+str(fileIndex)+'.jset', 'r') as file:\n",
    "        ytargetString = file.readline()[2:].rstrip()\n",
    "        lines = file.readlines()\n",
    "    ytargetList.append(np.fromstring(ytargetString, dtype=float, sep=','))\n",
    "    #dataList.append([np.fromstring(line, dtype=float, sep=',') for line in lines])\n",
    "    x = [np.fromstring(line, dtype=float, sep=',') for line in lines]\n",
    "    x = np.array(x)\n",
    "    for i in range(26):\n",
    "        for j in range(26):\n",
    "            x[i, j] = np.mean(x[i*20:(i+1)*20, j*20:(j+1)*20])\n",
    "    x = x[:26,:26].reshape(676)\n",
    "    #x = x.reshape(271441)\n",
    "    dataList.append(x)\n",
    "#convert lists into numpy matrices\n",
    "data = np.array(dataList)\n",
    "ytarget = np.array(ytargetList)\n",
    "print('data points:', data.shape)\n",
    "print('targets:', ytarget.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3qDYh0jOQOG"
   },
   "source": [
    "Visualize the four first data points $x$ as images along with their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "rUiZFgp7OQOG",
    "outputId": "d1e50fdc-89c2-433f-de30-1f9fcf4bad44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting example images\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "for ax, image, label in zip(axes, data[:4], ytarget[:4]):\n",
    "    image = image.reshape(26, 26)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title('y: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tFFvD07OQOH"
   },
   "source": [
    "# 3) Dimensionality reduction using a VAE (Variational Auto-Encoder)\n",
    "\n",
    "Source: https://avandekleut.github.io/vae/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we write the `Encoder` class by sublcassing `torch.nn.Module`, which lets us define the `__init__` method storing layers as an attribute, and a `forward` method describing the forward pass of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points: (10, 676)\n",
      "targets: (10, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data points:', data.shape)\n",
    "print('targets:', ytarget.shape)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(676, 512)\n",
    "        self.linear2 = nn.Linear(512, latent_dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return self.linear2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do something similar for the `Decoder` class, ensuring we reshape the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(latent_dims, 512)\n",
    "        self.linear2 = nn.Linear(512, 676)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.linear1(z))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        return z.reshape((-1, 1, 26, 26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write an `Autoencoder` class that combines these two. Note that we could have easily written this entire autoencoder as a single neural network, but splitting them in two makes it conceptually clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dims)\n",
    "        self.decoder = Decoder(latent_dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write some code to train the autoencoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, data, epochs=20):\n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for x, _ in data:\n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = autoencoder(x)\n",
    "            loss = ((x - x_hat)**2).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tFFvD07OQOH"
   },
   "source": [
    "# 3) Building a MLP (forward pass)\n",
    "\n",
    "Our goal is to build a feedforward neural network (MLP) to accurately classify these images of digits. We will feed a 64-dimensional input vector into the network and expect a 10-dimensional output vector, where element $i$ ($i \\in \\{0, \\ldots, 9\\}$) of the output vector corresponds to the network's estimated probability that the input image is showing the digit $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tFFvD07OQOH"
   },
   "source": [
    "# 3) Building a MLP (forward pass)\n",
    "\n",
    "Our goal is to build a feedforward neural network (MLP) to accurately classify these images of digits. We will feed a 64-dimensional input vector into the network and expect a 10-dimensional output vector, where element $i$ ($i \\in \\{0, \\ldots, 9\\}$) of the output vector corresponds to the network's estimated probability that the input image is showing the digit $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHXAdmyKOQOH"
   },
   "source": [
    "We first setup the model's hyperparameters - in our case we only specify the number of units in each layer of the network and `initial_scaling` - the scaling of our initial weight and bias values.\n",
    "\n",
    "Then we also initialize the model parameters - these are the weights and biases of the network in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syrTxMXROQOJ",
    "outputId": "a1ad3f6e-70ca-45a7-973f-e27ca38583d7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-215ebc6eafc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# network hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minitial_scaling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# network hyperparameters\n",
    "layers = [x.shape[1], 500, 500, ytarget.shape[1]]\n",
    "initial_scaling = 0.01\n",
    "\n",
    "# model parameters\n",
    "# list(tuple(weight_mat, bias_vec))\n",
    "params = [\n",
    "    (\n",
    "        # weights\n",
    "        np.random.normal(size=(layers[i+1], layers[i])) * initial_scaling,\n",
    "        # bias\n",
    "        np.random.normal(size=(layers[i+1],)) * initial_scaling\n",
    "    )\n",
    "    for i in range(len(layers)-1)\n",
    "]\n",
    "\n",
    "# check parameters\n",
    "print([list(map(lambda x: x.shape, params[i])) for i in range(len(params))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMeki1sROQOL"
   },
   "source": [
    "We implement the forward pass of the network as a function taking in the network parameters and the input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92r1SEs0OQOM"
   },
   "outputs": [],
   "source": [
    "def nn_forward(params, x):\n",
    "    # x: (x_dim) - vector!\n",
    "    state = x\n",
    "    # pass through input and hidden layers\n",
    "    for wi, bi in params[:-1]:\n",
    "        # first iteration\n",
    "        # state: (x_dim,)\n",
    "        # wi: (hid1_dim, x_dim)\n",
    "        # bi: (hid1_dim)\n",
    "        state = np.dot(wi, state) + bi\n",
    "        state = np.tanh(state)\n",
    "    # pass through output layer\n",
    "    wf, bf = params[-1]\n",
    "    logits = np.dot(wf, state) + bf\n",
    "    # softmax (normalize to prob distr)\n",
    "    return np.exp(logits) / np.sum(np.exp(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q97CIFaNOQOM",
    "outputId": "29595b82-e50c-4298-b8a3-042b251a4510"
   },
   "outputs": [],
   "source": [
    "# check forward pass\n",
    "ypred = nn_forward(params, x[0,:])\n",
    "print('ypred:', ypred)\n",
    "print('ypred sum:', ypred.sum())\n",
    "print('Predicted digit:', np.argmax(ypred) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kVOkp39OQOO"
   },
   "source": [
    "This is fine, but we are going to feed in around 2000 image vectors per training epoch (and potentially we will be training the network for many epochs). To do this more efficiently, we need to **batch** the inputs to the forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taOaJKuWOQOO"
   },
   "source": [
    "# 5) Batching (naive and using JAX)\n",
    "\n",
    "We will compare three different methods for implementing the batched forward pass:\n",
    "1. naive batching (for loop)\n",
    "2. rewriting function for input batches\n",
    "3. using JAX's vectorization function\n",
    "\n",
    "To learn more about JAX, visit https://github.com/google/jax. In short, JAX is a Python package to automatically differentiate, vectorize and optimize Python and NumPy programs with CPU, GPU, and TPU support. It is maintained by Google Research and actively using in Machine Learning and Neural Networks research at Google, DeepMind, and other leading high-performance ML research institutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqDrU62aOQOO"
   },
   "outputs": [],
   "source": [
    "# naive batching\n",
    "ypred = np.array([nn_forward(params, x[i, :]) for i in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ujtWNlOQOP"
   },
   "source": [
    "As you can imagine, this naive way of batching is not optimized at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ph2oGusoOQOP"
   },
   "outputs": [],
   "source": [
    "# rewriting function for input batches\n",
    "def nn_forward_batch(params, x):\n",
    "    # x: (batch_size, x_dim) - matrix\n",
    "    state = x\n",
    "    # pass through input and hidden layers\n",
    "    for wi, bi in params[:-1]:\n",
    "        # first iteration\n",
    "        # state: (batch_size, x_dim)\n",
    "        # wi: (hid1_dim, x_dim)\n",
    "        # bi: (hid1_dim)\n",
    "        state = np.dot(wi, state.T).T + bi # numpy broadcasting!\n",
    "        state = np.tanh(state)\n",
    "    # pass through output layer\n",
    "    wf, bf = params[-1]\n",
    "    logits = np.dot(wf, state.T).T + bf\n",
    "    # softmax (normalize to prob distr)\n",
    "    return (np.exp(logits).T / np.sum(np.exp(logits), axis=1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1No25p47OQOP"
   },
   "source": [
    "This is much better - instead of doing many vector operations sequentially, we are doing just one pass of matrix operations. This is great, but such a rewriting can be very time-consuming and for more complex functions, it can become a great source of bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaKEOGZNOQOQ"
   },
   "source": [
    "Next up, we will be using **JAX** to automatically vectorize (i.e. batch) our function. For this, we need to first rewrite our function from using `numpy` to using `jax.numpy` aka `jnp`. A key difference here is JAX's usage of keys for their pseudo-random number generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmPbxXwNOQOQ",
    "outputId": "3b421233-4bac-4986-8d82-5fba6e15833d"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# random key\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# JAX arrays -> device optimized\n",
    "a = jax.random.normal(key, (25, 35))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIY6a606OQOQ"
   },
   "source": [
    "Note the warning that JAX is *falling back to CPU*, implying that the default way of running JAX is on GPUs or TPUs. This is reflected in the JAX arrays being of type `DeviceArray` - with device-specific optimizations out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjLq1UAoOQOR",
    "outputId": "4e92b1b4-0d40-407b-c2ac-5bcdba3fce07"
   },
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr4FzDczOQOR"
   },
   "source": [
    "Simply replace `np` with `jnp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piURjU60OQOR"
   },
   "outputs": [],
   "source": [
    "def nn_forward_jnp(params, x):\n",
    "    # x: (x_dim) - vector!\n",
    "    state = x\n",
    "    # pass through input and hidden layers\n",
    "    for wi, bi in params[:-1]:\n",
    "        # first iteration\n",
    "        # state: (x_dim,)\n",
    "        # wi: (hid1_dim, x_dim)\n",
    "        # bi: (hid1_dim)\n",
    "        state = jnp.dot(wi, state) + bi\n",
    "        state = jnp.tanh(state)\n",
    "    # pass through output layer\n",
    "    wf, bf = params[-1]\n",
    "    logits = jnp.dot(wf, state) + bf\n",
    "    # softmax (normalize to prob distr)\n",
    "    return jnp.exp(logits) / jnp.sum(jnp.exp(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMFu_scNOQOS"
   },
   "source": [
    "Automatically vectorizing (batching) a function is a simple one-liner in JAX. The `in_axes` parameter indicates what axes of the function inputs will be used for the batching (we don't want to batch the network `params`, only the `x` input). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIviTavGOQOS"
   },
   "outputs": [],
   "source": [
    "nn_forward_batchd = jax.vmap(nn_forward_jnp, in_axes=(None, 0)) # that's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b12wGcGJOQOS"
   },
   "source": [
    "Let us run a time comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBnYATKkOQOS",
    "outputId": "9a847db5-834a-437d-d9e4-3ded34650678"
   },
   "outputs": [],
   "source": [
    "# naive batching\n",
    "%timeit np.array([nn_forward(params, x[i, :]) for i in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9Q-KOODOQOT",
    "outputId": "26777b53-35b2-46d4-e40e-23caca50e396"
   },
   "outputs": [],
   "source": [
    "# manual batching\n",
    "%timeit nn_forward_batch(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ma30hogUOQOT",
    "outputId": "c3de121d-fb81-4a20-b3b4-83a233a5add0"
   },
   "outputs": [],
   "source": [
    "# JAX batching\n",
    "%timeit nn_forward_batchd(params, jnp.array(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keVgqtiqOQOT"
   },
   "source": [
    "JAX even managed to outperform our own manual implementation of the batching!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enzK0VuSOQOT"
   },
   "source": [
    "# 6) Automatic differentiation\n",
    "\n",
    "In order to implement gradient descent, we could write a `backward_pass` function for the neural network and manually program in the differentiation of the loss function with respect to the network parameters. This is quite tedious. \n",
    "\n",
    "Instead, we will use *automatic differentiation*, which is used under the hood in pretty much every deep learning framework (TensorFlow, PyTorch, Keras, etc.). This is **not** finite differences (a numeric method) - finite differences produces prohibitive round-off errors, and is inefficient as it requires a forward pass for every parameter with respect to which you want to differentiate. Neither is it fully symbolic differentiation, which (often) leads to much redundancy in computing the derivatives (the deep learning framework `Theano` uses symbolic differentiation). \n",
    "\n",
    "You can think of automatic differentiation as symbolic differentiation on computer programs (instead of on math expressions). One of its modes (forward mode) is mathematically equivalent to evaluating a function using dual numbers of the form $x + \\dot x \\epsilon$.\n",
    "\n",
    "If you want to dive deeper into this (very interesting) topic, check out this [blog post](http://conal.net/blog/posts/what-is-automatic-differentiation-and-why-does-it-work) on automatic differentiation (or the accompanying [paper](http://conal.net/papers/beautiful-differentiation/beautiful-differentiation-long.pdf) and [presentation](https://vimeo.com/6622658)) or this [survey paper](https://jmlr.org/papers/volume18/17-468/17-468.pdf) on automatic differentiation in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjPV3OAQOQOU"
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return jnp.sin(x) * 2*x\n",
    "\n",
    "def backward(x):\n",
    "    return jnp.cos(x) * 2*x + 2*jnp.sin(x)\n",
    "\n",
    "backward_jax = jax.grad(forward) # that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWyuLIH3OQOU"
   },
   "outputs": [],
   "source": [
    "# demo\n",
    "inp = jnp.arange(0, 50., 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RO4MPXecOQOU"
   },
   "outputs": [],
   "source": [
    "# compute\n",
    "f = jax.vmap(forward)(inp)\n",
    "b = jax.vmap(backward)(inp)\n",
    "j = jax.vmap(backward_jax)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3LNLvyeIOQOV",
    "outputId": "083f6019-0d14-4d35-8d16-23e132c17bb3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,4))\n",
    "ax.plot(inp, f)\n",
    "ax.plot(inp, b, c='red')\n",
    "ax.plot(inp, j, c='green', ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz3oiK3mOQOV"
   },
   "source": [
    "# 7) MLP in JAX (forward and backward)\n",
    "\n",
    "We now use JAX's automatic differentiation to implement the backward step (gradient descent) for our MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zVIGZQYOQOV"
   },
   "outputs": [],
   "source": [
    "x = jnp.array(x)\n",
    "ytarget = jnp.array(ytarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ-4-0v9OQOV",
    "outputId": "38b07390-164c-422b-e5df-a700a0120f2f"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uLfhtSkOQOW"
   },
   "source": [
    "We need to also translate our initial code to use JAX's version of numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVuRRholOQOW",
    "outputId": "9d0250f3-e1c5-48c6-91b0-71bbda760731"
   },
   "outputs": [],
   "source": [
    "layers = [x.shape[1], 512, 512, ytarget.shape[1]]\n",
    "params = [\n",
    "    (\n",
    "        jax.random.normal(key, (layers[i+1], layers[i])) * 0.01,\n",
    "        jax.random.normal(key, (layers[i+1],)) * 0.01\n",
    "    )\n",
    "    for i in range(len(layers)-1)\n",
    "]\n",
    "print([list(map(lambda x: x.shape, params[i])) for i in range(len(params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izPqFwjWOQOX"
   },
   "outputs": [],
   "source": [
    "def nn_forward(params, x):\n",
    "    state = x\n",
    "    for wi, bi in params[:-1]:\n",
    "        state = jnp.dot(wi, state) + bi\n",
    "        state = jnp.tanh(state)\n",
    "    wf, bf = params[-1]\n",
    "    logits = jnp.dot(wf, state) + bf\n",
    "    return jnp.exp(logits) / jnp.sum(jnp.exp(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iAdJUnKOQOX"
   },
   "outputs": [],
   "source": [
    "nn_forward_batch = jax.vmap(nn_forward, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuy2M98sOQOX"
   },
   "source": [
    "Now, we can implement the MSE loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcA9wfrHOQOY"
   },
   "outputs": [],
   "source": [
    "def loss(params, x, ytarget):\n",
    "    # takes in batch!\n",
    "    # compute MSE loss\n",
    "    ypred = nn_forward_batch(params, x)\n",
    "    return jnp.square(ytarget - ypred).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lctlf8KvOQOY"
   },
   "source": [
    "We will also want to compute the accuracy for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Q8dktndOQOY"
   },
   "outputs": [],
   "source": [
    "def accuracy(params, x, ytarget):\n",
    "    # ypred (batch_size, y_dim)\n",
    "    ypred = nn_forward_batch(params, x)\n",
    "    return np.sum(ypred.argmax(axis=1) == ytarget.argmax(axis=1)) / ypred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwJlSWVEOQOZ"
   },
   "source": [
    "And we are ready to implement the gradient descent step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KL5rKV1POQOZ"
   },
   "outputs": [],
   "source": [
    "@jax.jit \n",
    "def update_params(params, x, ytarget, step_size=1e-2):\n",
    "    # does one epoch of training, then computes gradients, and one step of gradient descent\n",
    "    # returns updated weights\n",
    "    grads = jax.grad(loss)(params, x, ytarget)\n",
    "    return [\n",
    "        (\n",
    "            w - step_size * dw, \n",
    "            b - step_size * db\n",
    "        ) for (dw, db), (w, b) in zip(grads, params)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu1mpCMgOQOZ"
   },
   "source": [
    "Before we can train the network, we need to split our data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFo0iYJZOQOZ"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "permutation = jax.random.permutation(key, jnp.arange(x.shape[0]))\n",
    "x_shuffled = x[permutation]\n",
    "ytarget_shuffled = ytarget[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1wDugUbOQOZ"
   },
   "outputs": [],
   "source": [
    "# split 80:20\n",
    "n_train = int(x.shape[0] * 0.8)\n",
    "x_train = x_shuffled[:n_train]\n",
    "yt_train = ytarget_shuffled[:n_train]\n",
    "x_test = x_shuffled[n_train:]\n",
    "yt_test = ytarget_shuffled[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k_7UQlCOQOZ",
    "outputId": "ed33de51-9bd4-44d1-bc38-2034a46ea39e"
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyIbfNZiOQOa"
   },
   "outputs": [],
   "source": [
    "# save original (random) params\n",
    "orig_params = params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BL--AzDnOQOa",
    "outputId": "a268e198-3f81-4260-adf5-2e049056f96f"
   },
   "outputs": [],
   "source": [
    "# training procedure\n",
    "hist = []\n",
    "num_epochs = 200\n",
    "for i in range(num_epochs+1):\n",
    "    step_size=max((0.2 - i*0.0001, 0.01))\n",
    "    params = update_params(params, x_train, yt_train, step_size=step_size)\n",
    "    # test\n",
    "    test_loss = loss(params, x_test, yt_test)\n",
    "    test_acc = accuracy(params, x_test, yt_test)\n",
    "    # train\n",
    "    train_loss = loss(params, x_train, yt_train)\n",
    "    train_acc = accuracy(params, x_train, yt_train)\n",
    "    # print\n",
    "    if i % 10 == 0:\n",
    "        print('epoch {:3} testing {:6.2%} training {:6.2%}'.format(\n",
    "            i, test_acc, train_acc\n",
    "        ), end='\\n')\n",
    "    # save \n",
    "    hist.append((\n",
    "        test_loss, test_acc, train_loss, test_acc\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZmqdDhcOQOa"
   },
   "source": [
    "This is worse than we like. One should expect a MLP with two hidden layers to get to >90% accuracy. The reason for this might be that we are updating the weights only once per epoch. To change this, we can implement a mini-batching procedure - to split the dataset into batches and update the parameters after each batch. That way, we increase the number of gradient updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYpcpXjROQOa"
   },
   "outputs": [],
   "source": [
    "def minibatch_update(params, x_train, yt_train, step_size):\n",
    "    batch_size = 400\n",
    "    batch_idx = 0\n",
    "    while batch_idx*batch_size <= x_train.shape[0]:\n",
    "        params = update_params(params, x_train[batch_idx*batch_size:(batch_idx+1)*batch_size], yt_train[batch_idx*batch_size:(batch_idx+1)*batch_size], step_size=step_size)\n",
    "        batch_idx += 1\n",
    "    params = update_params(params, x_train[batch_idx*batch_size:], yt_train[batch_idx*batch_size:], step_size=step_size)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMWM2GK9OQOb"
   },
   "outputs": [],
   "source": [
    "# restore original params\n",
    "params = orig_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O305F3ItOQOb",
    "outputId": "41a1b5dd-af6b-4795-e6bc-0611c61b8a63"
   },
   "outputs": [],
   "source": [
    "# training procedure\n",
    "hist = []\n",
    "num_epochs = 200\n",
    "for i in range(num_epochs+1):\n",
    "    step_size=max((0.2 - i*0.0001, 0.01))\n",
    "    params = minibatch_update(params, x_train, yt_train, step_size=step_size)\n",
    "    # test\n",
    "    test_loss = loss(params, x_test, yt_test)\n",
    "    test_acc = accuracy(params, x_test, yt_test)\n",
    "    # train\n",
    "    train_loss = loss(params, x_train, yt_train)\n",
    "    train_acc = accuracy(params, x_train, yt_train)\n",
    "    # print\n",
    "    if i % 10 == 0:\n",
    "        print('epoch {:3} testing {:6.2%} training {:6.2%}'.format(\n",
    "            i, test_acc, train_acc\n",
    "        ), end='\\n')\n",
    "    # save \n",
    "    hist.append((\n",
    "        test_loss, test_acc, train_loss, test_acc\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R_5d0rmOQOb"
   },
   "source": [
    "And indeed, this helps us get to >95% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "WsU-S53UOQOb",
    "outputId": "af157eef-1ef9-49dd-bfdc-c40921d1d58b"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,4))\n",
    "axs[0].set_title('loss')\n",
    "axs[0].plot([e[0] for e in hist])\n",
    "axs[0].plot([e[2] for e in hist])\n",
    "axs[1].set_title('accuracy')\n",
    "axs[1].plot([e[1] for e in hist])\n",
    "axs[1].plot([e[3] for e in hist])\n",
    "axs[1].set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpUClpxLOQOd"
   },
   "source": [
    "# 8) MLP in Keras\n",
    "\n",
    "Now that we know how to implement a feedforward neural network manually, we can try using one of the deep learning frameworks to do the same thing. We will use Keras - it defines an API on top of TensorFlow and makes it very easy to build (simple) neural networks (somewhat sacrificing transparency/modifiability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMuHtUALOQOd"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGBNZmR2OQOd"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-Vb4_jGOQOe"
   },
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(500, input_shape=(64, ), activation='tanh'))\n",
    "model.add(keras.layers.Dense(500, activation='tanh'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SC0v7PkeOQOe",
    "outputId": "4382f261-a410-4852-fa8c-0c2159b940aa"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tu3lNMbaq1e"
   },
   "source": [
    "We now set up our learning algorithm. We are using stochastic gradient descent. We do not specify the batch size here and it is not obvious what is used. Looking at the Keras documentation (scroll down on [this page](https://keras.io/api/models/model_training_apis/)), we find that the `model.fit` method accepts a `batch_size` parameter. We do not specify it explicitly here, so Keras will use its default value of 32. This means that we will be doing mini batch gradient descent with a batch size of 32 (rather than 400, what we used in our JAX implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9Pb7f1oOQOe",
    "outputId": "2b1153a8-9427-4824-ac3f-039fc59154ed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='mse', metrics=['accuracy'])\n",
    "hist = model.fit(np.array(x_train), np.array(yt_train), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ybz7-ch2OQOf",
    "outputId": "5006717b-aff8-4a78-d30b-92e35f8b79a3"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n",
    "axs[0].set_title('train loss')\n",
    "axs[0].plot(hist.__dict__['history']['loss'])\n",
    "axs[1].set_title('train accuracy')\n",
    "axs[1].plot(hist.__dict__['history']['accuracy'])\n",
    "axs[1].set_ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUE_xEFXalar"
   },
   "source": [
    "Note that the accuracy reported here is on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ9ftf7DOQOf"
   },
   "source": [
    "# \"Dangers\" of using deep learning frameworks\n",
    "\n",
    "As you see here, Keras's ease of use is awesome. However, this easily leads to implement networks that you don't understand. While this can lead to good results, it is not what we want to see in your course projects. \n",
    "\n",
    "A good rule of thumb for your project: *don't use what you don't understand*.\n",
    "\n",
    "When implementing a neural network with JAX, you have to take control of every part of the design and training process. You will implement the loss function, the batching, the cross-validation scheme, the gradient step size, the update step (stochastic/batch/mini-batch, momentum, scheduling), early stopping, etc etc. Frameworks can easily obscure this away from you. Consider the model that you understand:\n",
    "```\n",
    "model.compile(optimizer='SGD',loss='mse', metrics=['accuracy'])\n",
    "```\n",
    "it uses stochastic gradient descent and the MSE loss. You should know and understand how this works. Now consider this simple change:\n",
    "```\n",
    "model.compile(optimizer='Adam',loss='cross-entropy', metrics=['accuracy'])\n",
    "```\n",
    "It is very easy to run this model and you will see your model converge much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsb9wzD2OQOf"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(500, input_shape=(64, ), activation='tanh'))\n",
    "model.add(keras.layers.Dense(500, activation='tanh'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "5yf-g-dcOQOf",
    "outputId": "1a71ca81-9b73-4066-cb52-487fbf72a819",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(np.array(x_train), np.array(yt_train), epochs=20, verbose=0)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n",
    "axs[0].set_title('train loss')\n",
    "axs[0].plot(hist.__dict__['history']['loss'])\n",
    "axs[1].set_title('train accuracy')\n",
    "axs[1].plot(hist.__dict__['history']['accuracy'])\n",
    "axs[1].set_ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfIykjrZOQOg"
   },
   "source": [
    "But why does this work? Most likely, you won't be able to answer this. You would need to understand what \"Adam\" does and what the \"categorical cross entropy\" loss is (links: [Adam](https://arxiv.org/abs/1412.6980), [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression)).\n",
    "\n",
    "In the course project report, we will expect you to understand (and explain) your network and why it performs better than your (or someone else's) baseline model. Therefore, make sure that you understand what you implement. \n",
    "\n",
    "Implementing your neural networks using a library like JAX will make it much easier to understand what you are building, to understand why something does or doesn't work, and it will give you a lot of insight that is usually obscured by these big deep learning frameworks.\n",
    "\n",
    "Note: [Haiku](https://github.com/deepmind/dm-haiku) is another library that is built on top of JAX to provide some commonly used constructs (similar to what Keras is to TensorFlow).\n",
    "\n",
    "This being said, you are free to use any library you want - just be mindful of the project requirements and think about what approach will give you the best return on invested time (in terms of quality of work and your personal learning outcome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvlRlivbb94D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NN AI Programming Tutorial 01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
